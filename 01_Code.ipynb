{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomindation System Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/abdelrahman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from flask import Flask, jsonify, request, redirect\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'jobs_data.csv'\n",
    "file_dir = !pwd\n",
    "file_dir = file_dir[0] + '/' + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file = pd.read_csv(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 entery of our Data\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>jobFunction</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Full Stack PHP Developer</td>\n",
       "      <td>['Engineering - Telecom/Technology', 'IT/Softw...</td>\n",
       "      <td>['Computer Software', 'Marketing and Advertisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CISCO Collaboration Specialist Engineer</td>\n",
       "      <td>['Installation/Maintenance/Repair', 'IT/Softwa...</td>\n",
       "      <td>['Information Technology Services']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Senior Back End-PHP Developer</td>\n",
       "      <td>['Engineering - Telecom/Technology', 'IT/Softw...</td>\n",
       "      <td>['Computer Software', 'Computer Networking']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>UX Designer</td>\n",
       "      <td>['Creative/Design/Art', 'IT/Software Developme...</td>\n",
       "      <td>['Computer Software', 'Information Technology ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Java Technical Lead</td>\n",
       "      <td>['Engineering - Telecom/Technology', 'IT/Softw...</td>\n",
       "      <td>['Computer Software', 'Information Technology ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                    title  \\\n",
       "0           0                 Full Stack PHP Developer   \n",
       "1           1  CISCO Collaboration Specialist Engineer   \n",
       "2           2            Senior Back End-PHP Developer   \n",
       "3           3                              UX Designer   \n",
       "4           4                      Java Technical Lead   \n",
       "\n",
       "                                         jobFunction  \\\n",
       "0  ['Engineering - Telecom/Technology', 'IT/Softw...   \n",
       "1  ['Installation/Maintenance/Repair', 'IT/Softwa...   \n",
       "2  ['Engineering - Telecom/Technology', 'IT/Softw...   \n",
       "3  ['Creative/Design/Art', 'IT/Software Developme...   \n",
       "4  ['Engineering - Telecom/Technology', 'IT/Softw...   \n",
       "\n",
       "                                            industry  \n",
       "0  ['Computer Software', 'Marketing and Advertisi...  \n",
       "1                ['Information Technology Services']  \n",
       "2       ['Computer Software', 'Computer Networking']  \n",
       "3  ['Computer Software', 'Information Technology ...  \n",
       "4  ['Computer Software', 'Information Technology ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"First 5 entery of our Data\\n\")\n",
    "df_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10870.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5434.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3138.043047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2717.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5434.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>8151.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>10869.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0\n",
       "count  10870.000000\n",
       "mean    5434.500000\n",
       "std     3138.043047\n",
       "min        0.000000\n",
       "25%     2717.250000\n",
       "50%     5434.500000\n",
       "75%     8151.750000\n",
       "max    10869.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data examples are\n",
      " 10870\n"
     ]
    }
   ],
   "source": [
    "print(\"Total data examples are\\n\", len(df_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Titles \n",
      " 3230\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Titles \\n\", len(df_file['title'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Titles \n",
      " 836\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Titles \\n\", len(df_file['jobFunction'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data examples after remove dublicated are\n",
      " 3230\n"
     ]
    }
   ],
   "source": [
    "df_file = df_file.drop_duplicates(subset='title')\n",
    "print(\"Total data examples after remove dublicated are\\n\", len(df_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns\n",
    "\n",
    "**some of columns are deleted that has no meaning and imact on our data like Unnamed: 0 and industry**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing Data\n",
    "\n",
    "## before we start to take a step  we need to handle our data\n",
    "\n",
    "**some of these handles are:**\n",
    "- braces\n",
    "- punctuation\n",
    "- quotes\n",
    "- Tokenization â€” convert sentences to words\n",
    "- Stemming  back word to its root like studying - study\n",
    "-  under_score ,stop words and other depends on user input because our data cleaned some of these \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(words):\n",
    "    '''\n",
    "    a fcuntion return cleaned text from punctuation, braces, quotes and others\n",
    "    argument:\n",
    "        string of words\n",
    "    return:\n",
    "        cleaned string\n",
    "    '''\n",
    "    words = list(words)\n",
    "    reqular_expression = '][,\"\\'/-_'\n",
    "    cleaned_words = \"\"\n",
    "    for word in words:\n",
    "        one_cleaned_word = \"\"\n",
    "        word = word.replace('/', ' ')\n",
    "        word = word.replace(']', ' ')\n",
    "        word = word.replace('[', ' ')\n",
    "        for c in word:\n",
    "            if not c.isdigit() and c not in reqular_expression:\n",
    "                one_cleaned_word +=c\n",
    "        cleaned_words +=one_cleaned_word\n",
    "    return cleaned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(words):\n",
    "    '''\n",
    "    a function return list of words without stop words\n",
    "    stop words like the,and, over and others english stopwords\n",
    "    argument:\n",
    "        string of words\n",
    "    return:\n",
    "        list of words\n",
    "    '''\n",
    "    words = word_tokenize(words)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean and drop dublicated rows from our data\n",
    "**some of our rows are repeated with the same data and we do not nead these dublicated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def file_cleaning(file):\n",
    "    '''\n",
    "    a function that return over all cleaned file\n",
    "    argument:\n",
    "        csv file\n",
    "    return:\n",
    "        cleaned file\n",
    "    '''\n",
    "    for key, value in file.iterrows():\n",
    "        value['title'] = clean_text(value['title'])\n",
    "        value['jobFunction'] = clean_text(value['jobFunction'])\n",
    "        cleaned_title = remove_stop_words(value['title'])\n",
    "        cleaned_function = remove_stop_words(value['jobFunction'])\n",
    "        value['title'] = ' '.join(map(str,cleaned_title)).lower()\n",
    "        value['jobFunction'] = ' '.join(map(str,cleaned_function)).lower()\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard_similarity_score(x, y):\n",
    "    \"\"\"\n",
    "        a function to return similarities between two string\n",
    "    argument:\n",
    "        x as  string which user_job_title\n",
    "        y for each of job title in our file\n",
    "    \"\"\"\n",
    "    intersection_cardinality = len(set(x).intersection(set(y)))\n",
    "    union_cardinality = len(set(x).union(set(y)))\n",
    "    return intersection_cardinality / float(union_cardinality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_similarity(job_title, title_list):\n",
    "    '''\n",
    "    function take a string and comapre its similarity\n",
    "    similarity for each job title with this title\n",
    "    argument:\n",
    "        user job_title, and all of our job_title\n",
    "    return:\n",
    "        sordted list of set with the weights and the index meet this weight in our data \n",
    "    '''\n",
    "    weighted_similarity = []\n",
    "    for indx, title in enumerate(title_list):\n",
    "        weights = compute_jaccard_similarity_score(title, job_title)\n",
    "        weighted_similarity.append((weights, indx))\n",
    "        weighted_similarity.sort(reverse=True)\n",
    "    return weighted_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_related_jobFunction(job_title, df_file_updated):\n",
    "    '''\n",
    "        this function return most frequent job function to user\n",
    "        argument:\n",
    "            user job_title, our data file\n",
    "        return:\n",
    "            most related 5 job function\n",
    "    '''\n",
    "    all_related_weighted_similarity = weighted_similarity(job_title, df_file_updated['title'])\n",
    "    most_related_jobs = []\n",
    "    for job in range(0, 2):\n",
    "        most_related_jobs.append(df_file_updated['jobFunction'][all_related_weighted_similarity[job][1]])\n",
    "    return most_related_jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation_model(file_to_clean, user_job_title):\n",
    "    '''\n",
    "        1 - clean the file data\n",
    "        2 - read cleaned file\n",
    "        3-  remove null values from cleaned file\n",
    "        4 - get related job function\n",
    "        argument:\n",
    "            file we need to clean for our recommendation\n",
    "        return:\n",
    "            related job function\n",
    "        \n",
    "    '''\n",
    "    df_file = file_to_clean.drop(['Unnamed: 0', 'industry'],axis=1)\n",
    "    df_file = file_cleaning(df_file)\n",
    "\n",
    "    dir_file = !pwd\n",
    "    path = dir_file[0]\n",
    "    df_file.to_csv(path + '/jobs_data_updated.csv', index=False)\n",
    "    df_file_updated = pd.read_csv(path+ '/jobs_data_updated.csv')\n",
    "    \n",
    "    df_file_updated =  df_file_updated.dropna()\n",
    "    \n",
    "    user_job_titl = user_job_title\n",
    "    most_jobfunction = most_related_jobFunction(user_job_title, df_file_updated)\n",
    "\n",
    "    return most_jobfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Most relevant jobs are\n",
      "\n",
      "['Mechanical', 'Telecom', 'Technology', 'Repair', 'Installation', 'Maintenance', 'Software', 'Engineering', 'Development', 'Electrical']\n"
     ]
    }
   ],
   "source": [
    "most_jobfunction = recommendation_model(df_file, \"CISCO Collaboration Specialist Engineer\")\n",
    "job_functions= set()\n",
    "for val in most_jobfunction:\n",
    "    words = remove_stop_words(val)\n",
    "    for word in words:\n",
    "        job_functions.add(word.capitalize())\n",
    "job_functions = list(job_functions)\n",
    "print(\"\\n\\nMost relevant jobs are\\n\")\n",
    "print(job_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Most relevant jobs are\n",
      "\n",
      "['Chain', 'Civil', 'Finance', 'Construction', 'Supply', 'Accounting', 'Sales', 'Architecture', 'Logistics', 'Engineering', 'Retail']\n"
     ]
    }
   ],
   "source": [
    "most_jobfunction = recommendation_model(df_file, \"Accountant\")\n",
    "job_functions= set()\n",
    "for val in most_jobfunction:\n",
    "    words = remove_stop_words(val)\n",
    "    for word in words:\n",
    "        job_functions.add(word.capitalize())\n",
    "job_functions = list(job_functions)\n",
    "print(\"\\n\\nMost relevant jobs are\\n\")\n",
    "print(job_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
